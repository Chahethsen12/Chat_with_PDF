{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXsMBOdHT8NbAeJg/Vu8FH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chahethsen12/Chat_with_PDF/blob/main/Chat_With_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "7E0YVOT4OS44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PqdnumxOO-v"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-groq langchain-community chromadb pypdf sentence-transformers\n",
        "print(\"RAG System libraries installed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup API Keys"
      ],
      "metadata": {
        "id": "yljiMLbaObrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from getpass import getpass\n",
        "\n",
        "# We only need Groq for the \"Thinking\" part.\n",
        "# We will use HuggingFace (free/local) for the \"Embedding\" part to save money/limit.\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API Key: \")"
      ],
      "metadata": {
        "id": "liW7t564OeK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The RAG Logic (The \"Brain\")**\n",
        "This code does three complex things in seconds:\n",
        "\n",
        "Ingest: Reads a PDF.\n",
        "Split: Cuts it into small chunks (so the AI doesn't get overwhelmed).\n",
        "Vectorize: Converts those chunks into math and stores them in a Vector Database."
      ],
      "metadata": {
        "id": "E41DjspDOixx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "def process_pdf_and_ask(pdf_path, user_question):\n",
        "    # 1. Load the PDF\n",
        "    print(\"üìÇ Loading PDF...\")\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    docs = loader.load()\n",
        "\n",
        "    # 2. Split into chunks (AI can't read a whole book at once)\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    splits = text_splitter.split_documents(docs)\n",
        "    print(f\"‚úÇÔ∏è Split document into {len(splits)} chunks.\")\n",
        "\n",
        "    # 3. Create Embeddings (Turn text into numbers)\n",
        "    # We use a free, powerful model from HuggingFace\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "    # 4. Store in Vector Database (Chroma)\n",
        "    print(\"üíæ Indexing data into Vector Database...\")\n",
        "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "\n",
        "    # 5. Setup the Retriever (The \"Librarian\")\n",
        "    retriever = vectorstore.as_retriever()\n",
        "\n",
        "    # 6. Setup the LLM (The \"Speaker\")\n",
        "    llm = ChatGroq(model_name=\"llama3-8b-8192\")\n",
        "\n",
        "    # 7. Create the Chat Chain\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever, chain_type=\"stuff\")\n",
        "\n",
        "    # 8. Ask the Question\n",
        "    print(\"ü§î Thinking...\")\n",
        "    response = qa_chain.run(user_question)\n",
        "\n",
        "    # Cleanup (to save RAM in Colab)\n",
        "    vectorstore.delete_collection()\n",
        "\n",
        "    return response\n",
        "\n",
        "print(\"RAG Function Ready!\")"
      ],
      "metadata": {
        "id": "unmLftQRO2cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run It\n",
        "For this to work, you need a PDF.\n",
        "\n",
        "Find a PDF on your computer (e.g., a resume, a small research paper, or a homework assignment).\n",
        "\n",
        "In Colab, click the Folder Icon üìÅ on the left sidebar.\n",
        "\n",
        "Drag and drop your PDF there.\n",
        "\n",
        "Update the pdf_filename below to match your file's name."
      ],
      "metadata": {
        "id": "Z7LoROyaO6EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE THIS NAME to the file you uploaded\n",
        "pdf_filename = \"sample.pdf\"\n",
        "\n",
        "# What do you want to ask your PDF?\n",
        "question = \"Summarize the main points of this document.\"\n",
        "\n",
        "# Run!\n",
        "try:\n",
        "    answer = process_pdf_and_ask(pdf_filename, question)\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"üìù AI ANSWER:\\n{answer}\")\n",
        "    print(\"=\"*50)\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: Please upload a PDF to the Colab files section first!\")"
      ],
      "metadata": {
        "id": "d-unOAL9PBtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}